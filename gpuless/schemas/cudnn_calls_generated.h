// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CUDNNCALLS_H_
#define FLATBUFFERS_GENERATED_CUDNNCALLS_H_

#include "flatbuffers/flatbuffers.h"

struct FBCudnnCreate;
struct FBCudnnCreateBuilder;

struct FBCudnnSetStream;
struct FBCudnnSetStreamBuilder;

struct FBCudnnCreateTensorDescriptor;
struct FBCudnnCreateTensorDescriptorBuilder;

struct FBCudnnSetTensorNdDescriptor;
struct FBCudnnSetTensorNdDescriptorBuilder;

struct FBCudnnCreateFilterDescriptor;
struct FBCudnnCreateFilterDescriptorBuilder;

struct FBCudnnSetFilterNdDescriptor;
struct FBCudnnSetFilterNdDescriptorBuilder;

struct FBCudnnCreateConvolutionDescriptor;
struct FBCudnnCreateConvolutionDescriptorBuilder;

struct FBCudnnSetConvolutionGroupCount;
struct FBCudnnSetConvolutionGroupCountBuilder;

struct FBCudnnSetConvolutionMathType;
struct FBCudnnSetConvolutionMathTypeBuilder;

struct FBCudnnSetConvolutionNdDescriptor;
struct FBCudnnSetConvolutionNdDescriptorBuilder;

struct FBCudnnConvolutionFwdAlgoPerf;
struct FBCudnnConvolutionFwdAlgoPerfBuilder;

struct FBCudnnGetConvolutionForwardAlgorithmV7;
struct FBCudnnGetConvolutionForwardAlgorithmV7Builder;

struct FBCudnnConvolutionForward;
struct FBCudnnConvolutionForwardBuilder;

struct FBCudnnBatchNormalizationForwardInference;
struct FBCudnnBatchNormalizationForwardInferenceBuilder;

struct FBCudnnDestroyConvolutionDescriptor;
struct FBCudnnDestroyConvolutionDescriptorBuilder;

struct FBCudnnDestroyFilterDescriptor;
struct FBCudnnDestroyFilterDescriptorBuilder;

struct FBCudnnDestroyTensorDescriptor;
struct FBCudnnDestroyTensorDescriptorBuilder;

struct FBCudnnConvolutionBackwardData;
struct FBCudnnConvolutionBackwardDataBuilder;

struct FBCudnnConvolutionBwdDataAlgoPerf;
struct FBCudnnConvolutionBwdDataAlgoPerfBuilder;

struct FBCudnnGetConvolutionBackwardDataAlgorithmV7;
struct FBCudnnGetConvolutionBackwardDataAlgorithmV7Builder;

struct FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize;
struct FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSizeBuilder;

struct FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize;
struct FBCudnnGetBatchNormalizationTrainingExReserveSpaceSizeBuilder;

struct FBCudnnBatchNormalizationForwardTrainingEx;
struct FBCudnnBatchNormalizationForwardTrainingExBuilder;

struct FBCudnnCreate FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnCreateBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           verifier.EndTable();
  }
};

struct FBCudnnCreateBuilder {
  typedef FBCudnnCreate Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnCreate::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  explicit FBCudnnCreateBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnCreate> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnCreate>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnCreate> CreateFBCudnnCreate(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0) {
  FBCudnnCreateBuilder builder_(_fbb);
  builder_.add_virtual_handle(virtual_handle);
  return builder_.Finish();
}

struct FBCudnnSetStream FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetStreamBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_STREAM = 6
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t stream() const {
    return GetField<uint64_t>(VT_STREAM, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_STREAM) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetStreamBuilder {
  typedef FBCudnnSetStream Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnSetStream::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_stream(uint64_t stream) {
    fbb_.AddElement<uint64_t>(FBCudnnSetStream::VT_STREAM, stream, 0);
  }
  explicit FBCudnnSetStreamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetStream> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetStream>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetStream> CreateFBCudnnSetStream(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t stream = 0) {
  FBCudnnSetStreamBuilder builder_(_fbb);
  builder_.add_stream(stream);
  builder_.add_virtual_handle(virtual_handle);
  return builder_.Finish();
}

struct FBCudnnCreateTensorDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnCreateTensorDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_TD = 4
  };
  uint64_t virtual_td() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD) &&
           verifier.EndTable();
  }
};

struct FBCudnnCreateTensorDescriptorBuilder {
  typedef FBCudnnCreateTensorDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_td(uint64_t virtual_td) {
    fbb_.AddElement<uint64_t>(FBCudnnCreateTensorDescriptor::VT_VIRTUAL_TD, virtual_td, 0);
  }
  explicit FBCudnnCreateTensorDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnCreateTensorDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnCreateTensorDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnCreateTensorDescriptor> CreateFBCudnnCreateTensorDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_td = 0) {
  FBCudnnCreateTensorDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_td(virtual_td);
  return builder_.Finish();
}

struct FBCudnnSetTensorNdDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetTensorNdDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_TD = 4,
    VT_DATA_TYPE = 6,
    VT_NB_DIMS = 8,
    VT_DIM_A = 10,
    VT_STRIDE_A = 12
  };
  uint64_t virtual_td() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD, 0);
  }
  uint64_t data_type() const {
    return GetField<uint64_t>(VT_DATA_TYPE, 0);
  }
  int32_t nb_dims() const {
    return GetField<int32_t>(VT_NB_DIMS, 0);
  }
  const flatbuffers::Vector<int32_t> *dim_a() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DIM_A);
  }
  const flatbuffers::Vector<int32_t> *stride_a() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDE_A);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD) &&
           VerifyField<uint64_t>(verifier, VT_DATA_TYPE) &&
           VerifyField<int32_t>(verifier, VT_NB_DIMS) &&
           VerifyOffset(verifier, VT_DIM_A) &&
           verifier.VerifyVector(dim_a()) &&
           VerifyOffset(verifier, VT_STRIDE_A) &&
           verifier.VerifyVector(stride_a()) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetTensorNdDescriptorBuilder {
  typedef FBCudnnSetTensorNdDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_td(uint64_t virtual_td) {
    fbb_.AddElement<uint64_t>(FBCudnnSetTensorNdDescriptor::VT_VIRTUAL_TD, virtual_td, 0);
  }
  void add_data_type(uint64_t data_type) {
    fbb_.AddElement<uint64_t>(FBCudnnSetTensorNdDescriptor::VT_DATA_TYPE, data_type, 0);
  }
  void add_nb_dims(int32_t nb_dims) {
    fbb_.AddElement<int32_t>(FBCudnnSetTensorNdDescriptor::VT_NB_DIMS, nb_dims, 0);
  }
  void add_dim_a(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim_a) {
    fbb_.AddOffset(FBCudnnSetTensorNdDescriptor::VT_DIM_A, dim_a);
  }
  void add_stride_a(flatbuffers::Offset<flatbuffers::Vector<int32_t>> stride_a) {
    fbb_.AddOffset(FBCudnnSetTensorNdDescriptor::VT_STRIDE_A, stride_a);
  }
  explicit FBCudnnSetTensorNdDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetTensorNdDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetTensorNdDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetTensorNdDescriptor> CreateFBCudnnSetTensorNdDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_td = 0,
    uint64_t data_type = 0,
    int32_t nb_dims = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> dim_a = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> stride_a = 0) {
  FBCudnnSetTensorNdDescriptorBuilder builder_(_fbb);
  builder_.add_data_type(data_type);
  builder_.add_virtual_td(virtual_td);
  builder_.add_stride_a(stride_a);
  builder_.add_dim_a(dim_a);
  builder_.add_nb_dims(nb_dims);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnSetTensorNdDescriptor> CreateFBCudnnSetTensorNdDescriptorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_td = 0,
    uint64_t data_type = 0,
    int32_t nb_dims = 0,
    const std::vector<int32_t> *dim_a = nullptr,
    const std::vector<int32_t> *stride_a = nullptr) {
  auto dim_a__ = dim_a ? _fbb.CreateVector<int32_t>(*dim_a) : 0;
  auto stride_a__ = stride_a ? _fbb.CreateVector<int32_t>(*stride_a) : 0;
  return CreateFBCudnnSetTensorNdDescriptor(
      _fbb,
      virtual_td,
      data_type,
      nb_dims,
      dim_a__,
      stride_a__);
}

struct FBCudnnCreateFilterDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnCreateFilterDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_FD = 4
  };
  uint64_t virtual_fd() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD) &&
           verifier.EndTable();
  }
};

struct FBCudnnCreateFilterDescriptorBuilder {
  typedef FBCudnnCreateFilterDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_fd(uint64_t virtual_fd) {
    fbb_.AddElement<uint64_t>(FBCudnnCreateFilterDescriptor::VT_VIRTUAL_FD, virtual_fd, 0);
  }
  explicit FBCudnnCreateFilterDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnCreateFilterDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnCreateFilterDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnCreateFilterDescriptor> CreateFBCudnnCreateFilterDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_fd = 0) {
  FBCudnnCreateFilterDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_fd(virtual_fd);
  return builder_.Finish();
}

struct FBCudnnSetFilterNdDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetFilterNdDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_FD = 4,
    VT_DATA_TYPE = 6,
    VT_FORMAT = 8,
    VT_NB_DIMS = 10,
    VT_FILTER_DIM_A = 12
  };
  uint64_t virtual_fd() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD, 0);
  }
  uint64_t data_type() const {
    return GetField<uint64_t>(VT_DATA_TYPE, 0);
  }
  uint64_t format() const {
    return GetField<uint64_t>(VT_FORMAT, 0);
  }
  int32_t nb_dims() const {
    return GetField<int32_t>(VT_NB_DIMS, 0);
  }
  const flatbuffers::Vector<int32_t> *filter_dim_a() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_FILTER_DIM_A);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD) &&
           VerifyField<uint64_t>(verifier, VT_DATA_TYPE) &&
           VerifyField<uint64_t>(verifier, VT_FORMAT) &&
           VerifyField<int32_t>(verifier, VT_NB_DIMS) &&
           VerifyOffset(verifier, VT_FILTER_DIM_A) &&
           verifier.VerifyVector(filter_dim_a()) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetFilterNdDescriptorBuilder {
  typedef FBCudnnSetFilterNdDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_fd(uint64_t virtual_fd) {
    fbb_.AddElement<uint64_t>(FBCudnnSetFilterNdDescriptor::VT_VIRTUAL_FD, virtual_fd, 0);
  }
  void add_data_type(uint64_t data_type) {
    fbb_.AddElement<uint64_t>(FBCudnnSetFilterNdDescriptor::VT_DATA_TYPE, data_type, 0);
  }
  void add_format(uint64_t format) {
    fbb_.AddElement<uint64_t>(FBCudnnSetFilterNdDescriptor::VT_FORMAT, format, 0);
  }
  void add_nb_dims(int32_t nb_dims) {
    fbb_.AddElement<int32_t>(FBCudnnSetFilterNdDescriptor::VT_NB_DIMS, nb_dims, 0);
  }
  void add_filter_dim_a(flatbuffers::Offset<flatbuffers::Vector<int32_t>> filter_dim_a) {
    fbb_.AddOffset(FBCudnnSetFilterNdDescriptor::VT_FILTER_DIM_A, filter_dim_a);
  }
  explicit FBCudnnSetFilterNdDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetFilterNdDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetFilterNdDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetFilterNdDescriptor> CreateFBCudnnSetFilterNdDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_fd = 0,
    uint64_t data_type = 0,
    uint64_t format = 0,
    int32_t nb_dims = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> filter_dim_a = 0) {
  FBCudnnSetFilterNdDescriptorBuilder builder_(_fbb);
  builder_.add_format(format);
  builder_.add_data_type(data_type);
  builder_.add_virtual_fd(virtual_fd);
  builder_.add_filter_dim_a(filter_dim_a);
  builder_.add_nb_dims(nb_dims);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnSetFilterNdDescriptor> CreateFBCudnnSetFilterNdDescriptorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_fd = 0,
    uint64_t data_type = 0,
    uint64_t format = 0,
    int32_t nb_dims = 0,
    const std::vector<int32_t> *filter_dim_a = nullptr) {
  auto filter_dim_a__ = filter_dim_a ? _fbb.CreateVector<int32_t>(*filter_dim_a) : 0;
  return CreateFBCudnnSetFilterNdDescriptor(
      _fbb,
      virtual_fd,
      data_type,
      format,
      nb_dims,
      filter_dim_a__);
}

struct FBCudnnCreateConvolutionDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnCreateConvolutionDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_CD = 4
  };
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           verifier.EndTable();
  }
};

struct FBCudnnCreateConvolutionDescriptorBuilder {
  typedef FBCudnnCreateConvolutionDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnCreateConvolutionDescriptor::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  explicit FBCudnnCreateConvolutionDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnCreateConvolutionDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnCreateConvolutionDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnCreateConvolutionDescriptor> CreateFBCudnnCreateConvolutionDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0) {
  FBCudnnCreateConvolutionDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_cd(virtual_cd);
  return builder_.Finish();
}

struct FBCudnnSetConvolutionGroupCount FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetConvolutionGroupCountBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_CD = 4,
    VT_GROUP_COUNT = 6
  };
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  int32_t group_count() const {
    return GetField<int32_t>(VT_GROUP_COUNT, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<int32_t>(verifier, VT_GROUP_COUNT) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetConvolutionGroupCountBuilder {
  typedef FBCudnnSetConvolutionGroupCount Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionGroupCount::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_group_count(int32_t group_count) {
    fbb_.AddElement<int32_t>(FBCudnnSetConvolutionGroupCount::VT_GROUP_COUNT, group_count, 0);
  }
  explicit FBCudnnSetConvolutionGroupCountBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetConvolutionGroupCount> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetConvolutionGroupCount>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetConvolutionGroupCount> CreateFBCudnnSetConvolutionGroupCount(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0,
    int32_t group_count = 0) {
  FBCudnnSetConvolutionGroupCountBuilder builder_(_fbb);
  builder_.add_virtual_cd(virtual_cd);
  builder_.add_group_count(group_count);
  return builder_.Finish();
}

struct FBCudnnSetConvolutionMathType FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetConvolutionMathTypeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_CD = 4,
    VT_MATH_TYPE = 6
  };
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  uint64_t math_type() const {
    return GetField<uint64_t>(VT_MATH_TYPE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<uint64_t>(verifier, VT_MATH_TYPE) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetConvolutionMathTypeBuilder {
  typedef FBCudnnSetConvolutionMathType Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionMathType::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_math_type(uint64_t math_type) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionMathType::VT_MATH_TYPE, math_type, 0);
  }
  explicit FBCudnnSetConvolutionMathTypeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetConvolutionMathType> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetConvolutionMathType>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetConvolutionMathType> CreateFBCudnnSetConvolutionMathType(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0,
    uint64_t math_type = 0) {
  FBCudnnSetConvolutionMathTypeBuilder builder_(_fbb);
  builder_.add_math_type(math_type);
  builder_.add_virtual_cd(virtual_cd);
  return builder_.Finish();
}

struct FBCudnnSetConvolutionNdDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnSetConvolutionNdDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_CD = 4,
    VT_ARRAY_LENGTH = 6,
    VT_PAD_A = 8,
    VT_FILTER_STRIDE_A = 10,
    VT_DILATION = 12,
    VT_CONVOLUTION_MODE = 14,
    VT_CUDNN_DATA_TYPE = 16
  };
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  int32_t array_length() const {
    return GetField<int32_t>(VT_ARRAY_LENGTH, 0);
  }
  const flatbuffers::Vector<int32_t> *pad_a() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PAD_A);
  }
  const flatbuffers::Vector<int32_t> *filter_stride_a() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_FILTER_STRIDE_A);
  }
  const flatbuffers::Vector<int32_t> *dilation() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DILATION);
  }
  uint64_t convolution_mode() const {
    return GetField<uint64_t>(VT_CONVOLUTION_MODE, 0);
  }
  uint64_t cudnn_data_type() const {
    return GetField<uint64_t>(VT_CUDNN_DATA_TYPE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<int32_t>(verifier, VT_ARRAY_LENGTH) &&
           VerifyOffset(verifier, VT_PAD_A) &&
           verifier.VerifyVector(pad_a()) &&
           VerifyOffset(verifier, VT_FILTER_STRIDE_A) &&
           verifier.VerifyVector(filter_stride_a()) &&
           VerifyOffset(verifier, VT_DILATION) &&
           verifier.VerifyVector(dilation()) &&
           VerifyField<uint64_t>(verifier, VT_CONVOLUTION_MODE) &&
           VerifyField<uint64_t>(verifier, VT_CUDNN_DATA_TYPE) &&
           verifier.EndTable();
  }
};

struct FBCudnnSetConvolutionNdDescriptorBuilder {
  typedef FBCudnnSetConvolutionNdDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionNdDescriptor::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_array_length(int32_t array_length) {
    fbb_.AddElement<int32_t>(FBCudnnSetConvolutionNdDescriptor::VT_ARRAY_LENGTH, array_length, 0);
  }
  void add_pad_a(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pad_a) {
    fbb_.AddOffset(FBCudnnSetConvolutionNdDescriptor::VT_PAD_A, pad_a);
  }
  void add_filter_stride_a(flatbuffers::Offset<flatbuffers::Vector<int32_t>> filter_stride_a) {
    fbb_.AddOffset(FBCudnnSetConvolutionNdDescriptor::VT_FILTER_STRIDE_A, filter_stride_a);
  }
  void add_dilation(flatbuffers::Offset<flatbuffers::Vector<int32_t>> dilation) {
    fbb_.AddOffset(FBCudnnSetConvolutionNdDescriptor::VT_DILATION, dilation);
  }
  void add_convolution_mode(uint64_t convolution_mode) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionNdDescriptor::VT_CONVOLUTION_MODE, convolution_mode, 0);
  }
  void add_cudnn_data_type(uint64_t cudnn_data_type) {
    fbb_.AddElement<uint64_t>(FBCudnnSetConvolutionNdDescriptor::VT_CUDNN_DATA_TYPE, cudnn_data_type, 0);
  }
  explicit FBCudnnSetConvolutionNdDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnSetConvolutionNdDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnSetConvolutionNdDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnSetConvolutionNdDescriptor> CreateFBCudnnSetConvolutionNdDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0,
    int32_t array_length = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pad_a = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> filter_stride_a = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> dilation = 0,
    uint64_t convolution_mode = 0,
    uint64_t cudnn_data_type = 0) {
  FBCudnnSetConvolutionNdDescriptorBuilder builder_(_fbb);
  builder_.add_cudnn_data_type(cudnn_data_type);
  builder_.add_convolution_mode(convolution_mode);
  builder_.add_virtual_cd(virtual_cd);
  builder_.add_dilation(dilation);
  builder_.add_filter_stride_a(filter_stride_a);
  builder_.add_pad_a(pad_a);
  builder_.add_array_length(array_length);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnSetConvolutionNdDescriptor> CreateFBCudnnSetConvolutionNdDescriptorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0,
    int32_t array_length = 0,
    const std::vector<int32_t> *pad_a = nullptr,
    const std::vector<int32_t> *filter_stride_a = nullptr,
    const std::vector<int32_t> *dilation = nullptr,
    uint64_t convolution_mode = 0,
    uint64_t cudnn_data_type = 0) {
  auto pad_a__ = pad_a ? _fbb.CreateVector<int32_t>(*pad_a) : 0;
  auto filter_stride_a__ = filter_stride_a ? _fbb.CreateVector<int32_t>(*filter_stride_a) : 0;
  auto dilation__ = dilation ? _fbb.CreateVector<int32_t>(*dilation) : 0;
  return CreateFBCudnnSetConvolutionNdDescriptor(
      _fbb,
      virtual_cd,
      array_length,
      pad_a__,
      filter_stride_a__,
      dilation__,
      convolution_mode,
      cudnn_data_type);
}

struct FBCudnnConvolutionFwdAlgoPerf FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnConvolutionFwdAlgoPerfBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALGO = 4,
    VT_STATUS = 6,
    VT_TIME = 8,
    VT_MEMORY = 10,
    VT_DETERMINISM = 12,
    VT_MATH_TYPE = 14,
    VT_RESERVED = 16
  };
  uint64_t algo() const {
    return GetField<uint64_t>(VT_ALGO, 0);
  }
  uint64_t status() const {
    return GetField<uint64_t>(VT_STATUS, 0);
  }
  float time() const {
    return GetField<float>(VT_TIME, 0.0f);
  }
  uint64_t memory() const {
    return GetField<uint64_t>(VT_MEMORY, 0);
  }
  uint64_t determinism() const {
    return GetField<uint64_t>(VT_DETERMINISM, 0);
  }
  uint64_t math_type() const {
    return GetField<uint64_t>(VT_MATH_TYPE, 0);
  }
  const flatbuffers::Vector<int32_t> *reserved() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_RESERVED);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_ALGO) &&
           VerifyField<uint64_t>(verifier, VT_STATUS) &&
           VerifyField<float>(verifier, VT_TIME) &&
           VerifyField<uint64_t>(verifier, VT_MEMORY) &&
           VerifyField<uint64_t>(verifier, VT_DETERMINISM) &&
           VerifyField<uint64_t>(verifier, VT_MATH_TYPE) &&
           VerifyOffset(verifier, VT_RESERVED) &&
           verifier.VerifyVector(reserved()) &&
           verifier.EndTable();
  }
};

struct FBCudnnConvolutionFwdAlgoPerfBuilder {
  typedef FBCudnnConvolutionFwdAlgoPerf Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_algo(uint64_t algo) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionFwdAlgoPerf::VT_ALGO, algo, 0);
  }
  void add_status(uint64_t status) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionFwdAlgoPerf::VT_STATUS, status, 0);
  }
  void add_time(float time) {
    fbb_.AddElement<float>(FBCudnnConvolutionFwdAlgoPerf::VT_TIME, time, 0.0f);
  }
  void add_memory(uint64_t memory) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionFwdAlgoPerf::VT_MEMORY, memory, 0);
  }
  void add_determinism(uint64_t determinism) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionFwdAlgoPerf::VT_DETERMINISM, determinism, 0);
  }
  void add_math_type(uint64_t math_type) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionFwdAlgoPerf::VT_MATH_TYPE, math_type, 0);
  }
  void add_reserved(flatbuffers::Offset<flatbuffers::Vector<int32_t>> reserved) {
    fbb_.AddOffset(FBCudnnConvolutionFwdAlgoPerf::VT_RESERVED, reserved);
  }
  explicit FBCudnnConvolutionFwdAlgoPerfBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf> CreateFBCudnnConvolutionFwdAlgoPerf(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t algo = 0,
    uint64_t status = 0,
    float time = 0.0f,
    uint64_t memory = 0,
    uint64_t determinism = 0,
    uint64_t math_type = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> reserved = 0) {
  FBCudnnConvolutionFwdAlgoPerfBuilder builder_(_fbb);
  builder_.add_math_type(math_type);
  builder_.add_determinism(determinism);
  builder_.add_memory(memory);
  builder_.add_status(status);
  builder_.add_algo(algo);
  builder_.add_reserved(reserved);
  builder_.add_time(time);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf> CreateFBCudnnConvolutionFwdAlgoPerfDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t algo = 0,
    uint64_t status = 0,
    float time = 0.0f,
    uint64_t memory = 0,
    uint64_t determinism = 0,
    uint64_t math_type = 0,
    const std::vector<int32_t> *reserved = nullptr) {
  auto reserved__ = reserved ? _fbb.CreateVector<int32_t>(*reserved) : 0;
  return CreateFBCudnnConvolutionFwdAlgoPerf(
      _fbb,
      algo,
      status,
      time,
      memory,
      determinism,
      math_type,
      reserved__);
}

struct FBCudnnGetConvolutionForwardAlgorithmV7 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnGetConvolutionForwardAlgorithmV7Builder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_VIRTUAL_TD_XDESC = 6,
    VT_VIRTUAL_TD_YDESC = 8,
    VT_VIRTUAL_FD = 10,
    VT_VIRTUAL_CD = 12,
    VT_REQUESTED_ALGO_COUNT = 14,
    VT_RETURNED_ALGO_COUNT = 16,
    VT_PERF_RESULTS = 18
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t virtual_td_ydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_YDESC, 0);
  }
  uint64_t virtual_fd() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD, 0);
  }
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  int32_t requested_algo_count() const {
    return GetField<int32_t>(VT_REQUESTED_ALGO_COUNT, 0);
  }
  int32_t returned_algo_count() const {
    return GetField<int32_t>(VT_RETURNED_ALGO_COUNT, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>> *perf_results() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>> *>(VT_PERF_RESULTS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_YDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<int32_t>(verifier, VT_REQUESTED_ALGO_COUNT) &&
           VerifyField<int32_t>(verifier, VT_RETURNED_ALGO_COUNT) &&
           VerifyOffset(verifier, VT_PERF_RESULTS) &&
           verifier.VerifyVector(perf_results()) &&
           verifier.VerifyVectorOfTables(perf_results()) &&
           verifier.EndTable();
  }
};

struct FBCudnnGetConvolutionForwardAlgorithmV7Builder {
  typedef FBCudnnGetConvolutionForwardAlgorithmV7 Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_virtual_td_ydesc(uint64_t virtual_td_ydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_VIRTUAL_TD_YDESC, virtual_td_ydesc, 0);
  }
  void add_virtual_fd(uint64_t virtual_fd) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_VIRTUAL_FD, virtual_fd, 0);
  }
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_requested_algo_count(int32_t requested_algo_count) {
    fbb_.AddElement<int32_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_REQUESTED_ALGO_COUNT, requested_algo_count, 0);
  }
  void add_returned_algo_count(int32_t returned_algo_count) {
    fbb_.AddElement<int32_t>(FBCudnnGetConvolutionForwardAlgorithmV7::VT_RETURNED_ALGO_COUNT, returned_algo_count, 0);
  }
  void add_perf_results(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>>> perf_results) {
    fbb_.AddOffset(FBCudnnGetConvolutionForwardAlgorithmV7::VT_PERF_RESULTS, perf_results);
  }
  explicit FBCudnnGetConvolutionForwardAlgorithmV7Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnGetConvolutionForwardAlgorithmV7> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnGetConvolutionForwardAlgorithmV7>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnGetConvolutionForwardAlgorithmV7> CreateFBCudnnGetConvolutionForwardAlgorithmV7(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t virtual_fd = 0,
    uint64_t virtual_cd = 0,
    int32_t requested_algo_count = 0,
    int32_t returned_algo_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>>> perf_results = 0) {
  FBCudnnGetConvolutionForwardAlgorithmV7Builder builder_(_fbb);
  builder_.add_virtual_cd(virtual_cd);
  builder_.add_virtual_fd(virtual_fd);
  builder_.add_virtual_td_ydesc(virtual_td_ydesc);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_perf_results(perf_results);
  builder_.add_returned_algo_count(returned_algo_count);
  builder_.add_requested_algo_count(requested_algo_count);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnGetConvolutionForwardAlgorithmV7> CreateFBCudnnGetConvolutionForwardAlgorithmV7Direct(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t virtual_fd = 0,
    uint64_t virtual_cd = 0,
    int32_t requested_algo_count = 0,
    int32_t returned_algo_count = 0,
    const std::vector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>> *perf_results = nullptr) {
  auto perf_results__ = perf_results ? _fbb.CreateVector<flatbuffers::Offset<FBCudnnConvolutionFwdAlgoPerf>>(*perf_results) : 0;
  return CreateFBCudnnGetConvolutionForwardAlgorithmV7(
      _fbb,
      virtual_handle,
      virtual_td_xdesc,
      virtual_td_ydesc,
      virtual_fd,
      virtual_cd,
      requested_algo_count,
      returned_algo_count,
      perf_results__);
}

struct FBCudnnConvolutionForward FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnConvolutionForwardBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_ALPHA = 6,
    VT_BETA = 8,
    VT_WORKSPACE = 10,
    VT_WORKSPACE_SIZE_IN_BYTES = 12,
    VT_VIRTUAL_CD = 14,
    VT_ALGO = 16,
    VT_VIRTUAL_FD_WDESC = 18,
    VT_W = 20,
    VT_VIRTUAL_TD_XDESC = 22,
    VT_X = 24,
    VT_VIRTUAL_TD_YDESC = 26,
    VT_Y = 28
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  const flatbuffers::Vector<uint8_t> *alpha() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_ALPHA);
  }
  const flatbuffers::Vector<uint8_t> *beta() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_BETA);
  }
  uint64_t workspace() const {
    return GetField<uint64_t>(VT_WORKSPACE, 0);
  }
  uint64_t workspace_size_in_bytes() const {
    return GetField<uint64_t>(VT_WORKSPACE_SIZE_IN_BYTES, 0);
  }
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  uint64_t algo() const {
    return GetField<uint64_t>(VT_ALGO, 0);
  }
  uint64_t virtual_fd_wdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD_WDESC, 0);
  }
  uint64_t w() const {
    return GetField<uint64_t>(VT_W, 0);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t x() const {
    return GetField<uint64_t>(VT_X, 0);
  }
  uint64_t virtual_td_ydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_YDESC, 0);
  }
  uint64_t y() const {
    return GetField<uint64_t>(VT_Y, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyOffset(verifier, VT_ALPHA) &&
           verifier.VerifyVector(alpha()) &&
           VerifyOffset(verifier, VT_BETA) &&
           verifier.VerifyVector(beta()) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE_SIZE_IN_BYTES) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<uint64_t>(verifier, VT_ALGO) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD_WDESC) &&
           VerifyField<uint64_t>(verifier, VT_W) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_X) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_YDESC) &&
           VerifyField<uint64_t>(verifier, VT_Y) &&
           verifier.EndTable();
  }
};

struct FBCudnnConvolutionForwardBuilder {
  typedef FBCudnnConvolutionForward Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_alpha(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha) {
    fbb_.AddOffset(FBCudnnConvolutionForward::VT_ALPHA, alpha);
  }
  void add_beta(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta) {
    fbb_.AddOffset(FBCudnnConvolutionForward::VT_BETA, beta);
  }
  void add_workspace(uint64_t workspace) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_WORKSPACE, workspace, 0);
  }
  void add_workspace_size_in_bytes(uint64_t workspace_size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_WORKSPACE_SIZE_IN_BYTES, workspace_size_in_bytes, 0);
  }
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_algo(uint64_t algo) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_ALGO, algo, 0);
  }
  void add_virtual_fd_wdesc(uint64_t virtual_fd_wdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_VIRTUAL_FD_WDESC, virtual_fd_wdesc, 0);
  }
  void add_w(uint64_t w) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_W, w, 0);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_x(uint64_t x) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_X, x, 0);
  }
  void add_virtual_td_ydesc(uint64_t virtual_td_ydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_VIRTUAL_TD_YDESC, virtual_td_ydesc, 0);
  }
  void add_y(uint64_t y) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionForward::VT_Y, y, 0);
  }
  explicit FBCudnnConvolutionForwardBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnConvolutionForward> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnConvolutionForward>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnConvolutionForward> CreateFBCudnnConvolutionForward(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta = 0,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    uint64_t virtual_cd = 0,
    uint64_t algo = 0,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t w = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y = 0) {
  FBCudnnConvolutionForwardBuilder builder_(_fbb);
  builder_.add_y(y);
  builder_.add_virtual_td_ydesc(virtual_td_ydesc);
  builder_.add_x(x);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_w(w);
  builder_.add_virtual_fd_wdesc(virtual_fd_wdesc);
  builder_.add_algo(algo);
  builder_.add_virtual_cd(virtual_cd);
  builder_.add_workspace_size_in_bytes(workspace_size_in_bytes);
  builder_.add_workspace(workspace);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_beta(beta);
  builder_.add_alpha(alpha);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnConvolutionForward> CreateFBCudnnConvolutionForwardDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    const std::vector<uint8_t> *alpha = nullptr,
    const std::vector<uint8_t> *beta = nullptr,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    uint64_t virtual_cd = 0,
    uint64_t algo = 0,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t w = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y = 0) {
  auto alpha__ = alpha ? _fbb.CreateVector<uint8_t>(*alpha) : 0;
  auto beta__ = beta ? _fbb.CreateVector<uint8_t>(*beta) : 0;
  return CreateFBCudnnConvolutionForward(
      _fbb,
      virtual_handle,
      alpha__,
      beta__,
      workspace,
      workspace_size_in_bytes,
      virtual_cd,
      algo,
      virtual_fd_wdesc,
      w,
      virtual_td_xdesc,
      x,
      virtual_td_ydesc,
      y);
}

struct FBCudnnBatchNormalizationForwardInference FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnBatchNormalizationForwardInferenceBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_MODE = 6,
    VT_ALPHA = 8,
    VT_BETA = 10,
    VT_VIRTUAL_TD_XDESC = 12,
    VT_X = 14,
    VT_VIRTUAL_TD_YDESC = 16,
    VT_Y = 18,
    VT_VIRTUAL_TD_BS_SCALE_BIAS_MEAN_VAR_DESC = 20,
    VT_BN_SCALE = 22,
    VT_BN_BIAS = 24,
    VT_ESTIMATED_MEAN = 26,
    VT_ESTIMATED_VARIANCE = 28,
    VT_EPSILON = 30
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t mode() const {
    return GetField<uint64_t>(VT_MODE, 0);
  }
  const flatbuffers::Vector<uint8_t> *alpha() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_ALPHA);
  }
  const flatbuffers::Vector<uint8_t> *beta() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_BETA);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t x() const {
    return GetField<uint64_t>(VT_X, 0);
  }
  uint64_t virtual_td_ydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_YDESC, 0);
  }
  uint64_t y() const {
    return GetField<uint64_t>(VT_Y, 0);
  }
  uint64_t virtual_td_bs_scale_bias_mean_var_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_BS_SCALE_BIAS_MEAN_VAR_DESC, 0);
  }
  uint64_t bn_scale() const {
    return GetField<uint64_t>(VT_BN_SCALE, 0);
  }
  uint64_t bn_bias() const {
    return GetField<uint64_t>(VT_BN_BIAS, 0);
  }
  uint64_t estimated_mean() const {
    return GetField<uint64_t>(VT_ESTIMATED_MEAN, 0);
  }
  uint64_t estimated_variance() const {
    return GetField<uint64_t>(VT_ESTIMATED_VARIANCE, 0);
  }
  double epsilon() const {
    return GetField<double>(VT_EPSILON, 0.0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_MODE) &&
           VerifyOffset(verifier, VT_ALPHA) &&
           verifier.VerifyVector(alpha()) &&
           VerifyOffset(verifier, VT_BETA) &&
           verifier.VerifyVector(beta()) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_X) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_YDESC) &&
           VerifyField<uint64_t>(verifier, VT_Y) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_BS_SCALE_BIAS_MEAN_VAR_DESC) &&
           VerifyField<uint64_t>(verifier, VT_BN_SCALE) &&
           VerifyField<uint64_t>(verifier, VT_BN_BIAS) &&
           VerifyField<uint64_t>(verifier, VT_ESTIMATED_MEAN) &&
           VerifyField<uint64_t>(verifier, VT_ESTIMATED_VARIANCE) &&
           VerifyField<double>(verifier, VT_EPSILON) &&
           verifier.EndTable();
  }
};

struct FBCudnnBatchNormalizationForwardInferenceBuilder {
  typedef FBCudnnBatchNormalizationForwardInference Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_mode(uint64_t mode) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_MODE, mode, 0);
  }
  void add_alpha(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha) {
    fbb_.AddOffset(FBCudnnBatchNormalizationForwardInference::VT_ALPHA, alpha);
  }
  void add_beta(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta) {
    fbb_.AddOffset(FBCudnnBatchNormalizationForwardInference::VT_BETA, beta);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_x(uint64_t x) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_X, x, 0);
  }
  void add_virtual_td_ydesc(uint64_t virtual_td_ydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_VIRTUAL_TD_YDESC, virtual_td_ydesc, 0);
  }
  void add_y(uint64_t y) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_Y, y, 0);
  }
  void add_virtual_td_bs_scale_bias_mean_var_desc(uint64_t virtual_td_bs_scale_bias_mean_var_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_VIRTUAL_TD_BS_SCALE_BIAS_MEAN_VAR_DESC, virtual_td_bs_scale_bias_mean_var_desc, 0);
  }
  void add_bn_scale(uint64_t bn_scale) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_BN_SCALE, bn_scale, 0);
  }
  void add_bn_bias(uint64_t bn_bias) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_BN_BIAS, bn_bias, 0);
  }
  void add_estimated_mean(uint64_t estimated_mean) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_ESTIMATED_MEAN, estimated_mean, 0);
  }
  void add_estimated_variance(uint64_t estimated_variance) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardInference::VT_ESTIMATED_VARIANCE, estimated_variance, 0);
  }
  void add_epsilon(double epsilon) {
    fbb_.AddElement<double>(FBCudnnBatchNormalizationForwardInference::VT_EPSILON, epsilon, 0.0);
  }
  explicit FBCudnnBatchNormalizationForwardInferenceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnBatchNormalizationForwardInference> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnBatchNormalizationForwardInference>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnBatchNormalizationForwardInference> CreateFBCudnnBatchNormalizationForwardInference(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y = 0,
    uint64_t virtual_td_bs_scale_bias_mean_var_desc = 0,
    uint64_t bn_scale = 0,
    uint64_t bn_bias = 0,
    uint64_t estimated_mean = 0,
    uint64_t estimated_variance = 0,
    double epsilon = 0.0) {
  FBCudnnBatchNormalizationForwardInferenceBuilder builder_(_fbb);
  builder_.add_epsilon(epsilon);
  builder_.add_estimated_variance(estimated_variance);
  builder_.add_estimated_mean(estimated_mean);
  builder_.add_bn_bias(bn_bias);
  builder_.add_bn_scale(bn_scale);
  builder_.add_virtual_td_bs_scale_bias_mean_var_desc(virtual_td_bs_scale_bias_mean_var_desc);
  builder_.add_y(y);
  builder_.add_virtual_td_ydesc(virtual_td_ydesc);
  builder_.add_x(x);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_mode(mode);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_beta(beta);
  builder_.add_alpha(alpha);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnBatchNormalizationForwardInference> CreateFBCudnnBatchNormalizationForwardInferenceDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    const std::vector<uint8_t> *alpha = nullptr,
    const std::vector<uint8_t> *beta = nullptr,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y = 0,
    uint64_t virtual_td_bs_scale_bias_mean_var_desc = 0,
    uint64_t bn_scale = 0,
    uint64_t bn_bias = 0,
    uint64_t estimated_mean = 0,
    uint64_t estimated_variance = 0,
    double epsilon = 0.0) {
  auto alpha__ = alpha ? _fbb.CreateVector<uint8_t>(*alpha) : 0;
  auto beta__ = beta ? _fbb.CreateVector<uint8_t>(*beta) : 0;
  return CreateFBCudnnBatchNormalizationForwardInference(
      _fbb,
      virtual_handle,
      mode,
      alpha__,
      beta__,
      virtual_td_xdesc,
      x,
      virtual_td_ydesc,
      y,
      virtual_td_bs_scale_bias_mean_var_desc,
      bn_scale,
      bn_bias,
      estimated_mean,
      estimated_variance,
      epsilon);
}

struct FBCudnnDestroyConvolutionDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnDestroyConvolutionDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_CD = 4
  };
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           verifier.EndTable();
  }
};

struct FBCudnnDestroyConvolutionDescriptorBuilder {
  typedef FBCudnnDestroyConvolutionDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnDestroyConvolutionDescriptor::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  explicit FBCudnnDestroyConvolutionDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnDestroyConvolutionDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnDestroyConvolutionDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnDestroyConvolutionDescriptor> CreateFBCudnnDestroyConvolutionDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_cd = 0) {
  FBCudnnDestroyConvolutionDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_cd(virtual_cd);
  return builder_.Finish();
}

struct FBCudnnDestroyFilterDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnDestroyFilterDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_FD = 4
  };
  uint64_t virtual_fd() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD) &&
           verifier.EndTable();
  }
};

struct FBCudnnDestroyFilterDescriptorBuilder {
  typedef FBCudnnDestroyFilterDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_fd(uint64_t virtual_fd) {
    fbb_.AddElement<uint64_t>(FBCudnnDestroyFilterDescriptor::VT_VIRTUAL_FD, virtual_fd, 0);
  }
  explicit FBCudnnDestroyFilterDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnDestroyFilterDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnDestroyFilterDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnDestroyFilterDescriptor> CreateFBCudnnDestroyFilterDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_fd = 0) {
  FBCudnnDestroyFilterDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_fd(virtual_fd);
  return builder_.Finish();
}

struct FBCudnnDestroyTensorDescriptor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnDestroyTensorDescriptorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_TD = 4
  };
  uint64_t virtual_td() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD) &&
           verifier.EndTable();
  }
};

struct FBCudnnDestroyTensorDescriptorBuilder {
  typedef FBCudnnDestroyTensorDescriptor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_td(uint64_t virtual_td) {
    fbb_.AddElement<uint64_t>(FBCudnnDestroyTensorDescriptor::VT_VIRTUAL_TD, virtual_td, 0);
  }
  explicit FBCudnnDestroyTensorDescriptorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnDestroyTensorDescriptor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnDestroyTensorDescriptor>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnDestroyTensorDescriptor> CreateFBCudnnDestroyTensorDescriptor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_td = 0) {
  FBCudnnDestroyTensorDescriptorBuilder builder_(_fbb);
  builder_.add_virtual_td(virtual_td);
  return builder_.Finish();
}

struct FBCudnnConvolutionBackwardData FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnConvolutionBackwardDataBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_ALPHA = 6,
    VT_VIRTUAL_FD_WDESC = 8,
    VT_W = 10,
    VT_VIRTUAL_TD_DYDESC = 12,
    VT_DY = 14,
    VT_VIRTUAL_CD = 16,
    VT_ALGO = 18,
    VT_WORKSPACE = 20,
    VT_WORKSPACE_SIZE_IN_BYTES = 22,
    VT_BETA = 24,
    VT_VIRTUAL_TD_DXDESC = 26,
    VT_DX = 28
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  const flatbuffers::Vector<uint8_t> *alpha() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_ALPHA);
  }
  uint64_t virtual_fd_wdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD_WDESC, 0);
  }
  uint64_t w() const {
    return GetField<uint64_t>(VT_W, 0);
  }
  uint64_t virtual_td_dydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_DYDESC, 0);
  }
  uint64_t dy() const {
    return GetField<uint64_t>(VT_DY, 0);
  }
  uint64_t virtual_cd() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD, 0);
  }
  uint64_t algo() const {
    return GetField<uint64_t>(VT_ALGO, 0);
  }
  uint64_t workspace() const {
    return GetField<uint64_t>(VT_WORKSPACE, 0);
  }
  uint64_t workspace_size_in_bytes() const {
    return GetField<uint64_t>(VT_WORKSPACE_SIZE_IN_BYTES, 0);
  }
  const flatbuffers::Vector<uint8_t> *beta() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_BETA);
  }
  uint64_t virtual_td_dxdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_DXDESC, 0);
  }
  uint64_t dx() const {
    return GetField<uint64_t>(VT_DX, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyOffset(verifier, VT_ALPHA) &&
           verifier.VerifyVector(alpha()) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD_WDESC) &&
           VerifyField<uint64_t>(verifier, VT_W) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_DYDESC) &&
           VerifyField<uint64_t>(verifier, VT_DY) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD) &&
           VerifyField<uint64_t>(verifier, VT_ALGO) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE_SIZE_IN_BYTES) &&
           VerifyOffset(verifier, VT_BETA) &&
           verifier.VerifyVector(beta()) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_DXDESC) &&
           VerifyField<uint64_t>(verifier, VT_DX) &&
           verifier.EndTable();
  }
};

struct FBCudnnConvolutionBackwardDataBuilder {
  typedef FBCudnnConvolutionBackwardData Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_alpha(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha) {
    fbb_.AddOffset(FBCudnnConvolutionBackwardData::VT_ALPHA, alpha);
  }
  void add_virtual_fd_wdesc(uint64_t virtual_fd_wdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_VIRTUAL_FD_WDESC, virtual_fd_wdesc, 0);
  }
  void add_w(uint64_t w) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_W, w, 0);
  }
  void add_virtual_td_dydesc(uint64_t virtual_td_dydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_VIRTUAL_TD_DYDESC, virtual_td_dydesc, 0);
  }
  void add_dy(uint64_t dy) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_DY, dy, 0);
  }
  void add_virtual_cd(uint64_t virtual_cd) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_VIRTUAL_CD, virtual_cd, 0);
  }
  void add_algo(uint64_t algo) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_ALGO, algo, 0);
  }
  void add_workspace(uint64_t workspace) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_WORKSPACE, workspace, 0);
  }
  void add_workspace_size_in_bytes(uint64_t workspace_size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_WORKSPACE_SIZE_IN_BYTES, workspace_size_in_bytes, 0);
  }
  void add_beta(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta) {
    fbb_.AddOffset(FBCudnnConvolutionBackwardData::VT_BETA, beta);
  }
  void add_virtual_td_dxdesc(uint64_t virtual_td_dxdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_VIRTUAL_TD_DXDESC, virtual_td_dxdesc, 0);
  }
  void add_dx(uint64_t dx) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBackwardData::VT_DX, dx, 0);
  }
  explicit FBCudnnConvolutionBackwardDataBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnConvolutionBackwardData> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnConvolutionBackwardData>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnConvolutionBackwardData> CreateFBCudnnConvolutionBackwardData(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha = 0,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t w = 0,
    uint64_t virtual_td_dydesc = 0,
    uint64_t dy = 0,
    uint64_t virtual_cd = 0,
    uint64_t algo = 0,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta = 0,
    uint64_t virtual_td_dxdesc = 0,
    uint64_t dx = 0) {
  FBCudnnConvolutionBackwardDataBuilder builder_(_fbb);
  builder_.add_dx(dx);
  builder_.add_virtual_td_dxdesc(virtual_td_dxdesc);
  builder_.add_workspace_size_in_bytes(workspace_size_in_bytes);
  builder_.add_workspace(workspace);
  builder_.add_algo(algo);
  builder_.add_virtual_cd(virtual_cd);
  builder_.add_dy(dy);
  builder_.add_virtual_td_dydesc(virtual_td_dydesc);
  builder_.add_w(w);
  builder_.add_virtual_fd_wdesc(virtual_fd_wdesc);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_beta(beta);
  builder_.add_alpha(alpha);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnConvolutionBackwardData> CreateFBCudnnConvolutionBackwardDataDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    const std::vector<uint8_t> *alpha = nullptr,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t w = 0,
    uint64_t virtual_td_dydesc = 0,
    uint64_t dy = 0,
    uint64_t virtual_cd = 0,
    uint64_t algo = 0,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    const std::vector<uint8_t> *beta = nullptr,
    uint64_t virtual_td_dxdesc = 0,
    uint64_t dx = 0) {
  auto alpha__ = alpha ? _fbb.CreateVector<uint8_t>(*alpha) : 0;
  auto beta__ = beta ? _fbb.CreateVector<uint8_t>(*beta) : 0;
  return CreateFBCudnnConvolutionBackwardData(
      _fbb,
      virtual_handle,
      alpha__,
      virtual_fd_wdesc,
      w,
      virtual_td_dydesc,
      dy,
      virtual_cd,
      algo,
      workspace,
      workspace_size_in_bytes,
      beta__,
      virtual_td_dxdesc,
      dx);
}

struct FBCudnnConvolutionBwdDataAlgoPerf FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnConvolutionBwdDataAlgoPerfBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALGO = 4,
    VT_STATUS = 6,
    VT_TIME = 8,
    VT_MEMORY = 10,
    VT_DETERMINISM = 12,
    VT_MATH_TYPE = 14,
    VT_RESERVED = 16
  };
  uint64_t algo() const {
    return GetField<uint64_t>(VT_ALGO, 0);
  }
  uint64_t status() const {
    return GetField<uint64_t>(VT_STATUS, 0);
  }
  float time() const {
    return GetField<float>(VT_TIME, 0.0f);
  }
  uint64_t memory() const {
    return GetField<uint64_t>(VT_MEMORY, 0);
  }
  uint64_t determinism() const {
    return GetField<uint64_t>(VT_DETERMINISM, 0);
  }
  uint64_t math_type() const {
    return GetField<uint64_t>(VT_MATH_TYPE, 0);
  }
  const flatbuffers::Vector<int32_t> *reserved() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_RESERVED);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_ALGO) &&
           VerifyField<uint64_t>(verifier, VT_STATUS) &&
           VerifyField<float>(verifier, VT_TIME) &&
           VerifyField<uint64_t>(verifier, VT_MEMORY) &&
           VerifyField<uint64_t>(verifier, VT_DETERMINISM) &&
           VerifyField<uint64_t>(verifier, VT_MATH_TYPE) &&
           VerifyOffset(verifier, VT_RESERVED) &&
           verifier.VerifyVector(reserved()) &&
           verifier.EndTable();
  }
};

struct FBCudnnConvolutionBwdDataAlgoPerfBuilder {
  typedef FBCudnnConvolutionBwdDataAlgoPerf Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_algo(uint64_t algo) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBwdDataAlgoPerf::VT_ALGO, algo, 0);
  }
  void add_status(uint64_t status) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBwdDataAlgoPerf::VT_STATUS, status, 0);
  }
  void add_time(float time) {
    fbb_.AddElement<float>(FBCudnnConvolutionBwdDataAlgoPerf::VT_TIME, time, 0.0f);
  }
  void add_memory(uint64_t memory) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBwdDataAlgoPerf::VT_MEMORY, memory, 0);
  }
  void add_determinism(uint64_t determinism) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBwdDataAlgoPerf::VT_DETERMINISM, determinism, 0);
  }
  void add_math_type(uint64_t math_type) {
    fbb_.AddElement<uint64_t>(FBCudnnConvolutionBwdDataAlgoPerf::VT_MATH_TYPE, math_type, 0);
  }
  void add_reserved(flatbuffers::Offset<flatbuffers::Vector<int32_t>> reserved) {
    fbb_.AddOffset(FBCudnnConvolutionBwdDataAlgoPerf::VT_RESERVED, reserved);
  }
  explicit FBCudnnConvolutionBwdDataAlgoPerfBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf> CreateFBCudnnConvolutionBwdDataAlgoPerf(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t algo = 0,
    uint64_t status = 0,
    float time = 0.0f,
    uint64_t memory = 0,
    uint64_t determinism = 0,
    uint64_t math_type = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> reserved = 0) {
  FBCudnnConvolutionBwdDataAlgoPerfBuilder builder_(_fbb);
  builder_.add_math_type(math_type);
  builder_.add_determinism(determinism);
  builder_.add_memory(memory);
  builder_.add_status(status);
  builder_.add_algo(algo);
  builder_.add_reserved(reserved);
  builder_.add_time(time);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf> CreateFBCudnnConvolutionBwdDataAlgoPerfDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t algo = 0,
    uint64_t status = 0,
    float time = 0.0f,
    uint64_t memory = 0,
    uint64_t determinism = 0,
    uint64_t math_type = 0,
    const std::vector<int32_t> *reserved = nullptr) {
  auto reserved__ = reserved ? _fbb.CreateVector<int32_t>(*reserved) : 0;
  return CreateFBCudnnConvolutionBwdDataAlgoPerf(
      _fbb,
      algo,
      status,
      time,
      memory,
      determinism,
      math_type,
      reserved__);
}

struct FBCudnnGetConvolutionBackwardDataAlgorithmV7 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnGetConvolutionBackwardDataAlgorithmV7Builder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_VIRTUAL_FD_WDESC = 6,
    VT_VIRTUAL_TD_DYDESC = 8,
    VT_VIRTUAL_CD_CONVDESC = 10,
    VT_VIRTUAL_TD_DXDESC = 12,
    VT_REQUESTED_ALGO_COUNT = 14,
    VT_RETURNED_ALGO_COUNT = 16,
    VT_PERF_RESULTS = 18
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t virtual_fd_wdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_FD_WDESC, 0);
  }
  uint64_t virtual_td_dydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_DYDESC, 0);
  }
  uint64_t virtual_cd_convdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_CD_CONVDESC, 0);
  }
  uint64_t virtual_td_dxdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_DXDESC, 0);
  }
  int32_t requested_algo_count() const {
    return GetField<int32_t>(VT_REQUESTED_ALGO_COUNT, 0);
  }
  int32_t returned_algo_count() const {
    return GetField<int32_t>(VT_RETURNED_ALGO_COUNT, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>> *perf_results() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>> *>(VT_PERF_RESULTS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_FD_WDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_DYDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_CD_CONVDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_DXDESC) &&
           VerifyField<int32_t>(verifier, VT_REQUESTED_ALGO_COUNT) &&
           VerifyField<int32_t>(verifier, VT_RETURNED_ALGO_COUNT) &&
           VerifyOffset(verifier, VT_PERF_RESULTS) &&
           verifier.VerifyVector(perf_results()) &&
           verifier.VerifyVectorOfTables(perf_results()) &&
           verifier.EndTable();
  }
};

struct FBCudnnGetConvolutionBackwardDataAlgorithmV7Builder {
  typedef FBCudnnGetConvolutionBackwardDataAlgorithmV7 Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_virtual_fd_wdesc(uint64_t virtual_fd_wdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_VIRTUAL_FD_WDESC, virtual_fd_wdesc, 0);
  }
  void add_virtual_td_dydesc(uint64_t virtual_td_dydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_VIRTUAL_TD_DYDESC, virtual_td_dydesc, 0);
  }
  void add_virtual_cd_convdesc(uint64_t virtual_cd_convdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_VIRTUAL_CD_CONVDESC, virtual_cd_convdesc, 0);
  }
  void add_virtual_td_dxdesc(uint64_t virtual_td_dxdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_VIRTUAL_TD_DXDESC, virtual_td_dxdesc, 0);
  }
  void add_requested_algo_count(int32_t requested_algo_count) {
    fbb_.AddElement<int32_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_REQUESTED_ALGO_COUNT, requested_algo_count, 0);
  }
  void add_returned_algo_count(int32_t returned_algo_count) {
    fbb_.AddElement<int32_t>(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_RETURNED_ALGO_COUNT, returned_algo_count, 0);
  }
  void add_perf_results(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>>> perf_results) {
    fbb_.AddOffset(FBCudnnGetConvolutionBackwardDataAlgorithmV7::VT_PERF_RESULTS, perf_results);
  }
  explicit FBCudnnGetConvolutionBackwardDataAlgorithmV7Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnGetConvolutionBackwardDataAlgorithmV7> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnGetConvolutionBackwardDataAlgorithmV7>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnGetConvolutionBackwardDataAlgorithmV7> CreateFBCudnnGetConvolutionBackwardDataAlgorithmV7(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t virtual_td_dydesc = 0,
    uint64_t virtual_cd_convdesc = 0,
    uint64_t virtual_td_dxdesc = 0,
    int32_t requested_algo_count = 0,
    int32_t returned_algo_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>>> perf_results = 0) {
  FBCudnnGetConvolutionBackwardDataAlgorithmV7Builder builder_(_fbb);
  builder_.add_virtual_td_dxdesc(virtual_td_dxdesc);
  builder_.add_virtual_cd_convdesc(virtual_cd_convdesc);
  builder_.add_virtual_td_dydesc(virtual_td_dydesc);
  builder_.add_virtual_fd_wdesc(virtual_fd_wdesc);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_perf_results(perf_results);
  builder_.add_returned_algo_count(returned_algo_count);
  builder_.add_requested_algo_count(requested_algo_count);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnGetConvolutionBackwardDataAlgorithmV7> CreateFBCudnnGetConvolutionBackwardDataAlgorithmV7Direct(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t virtual_fd_wdesc = 0,
    uint64_t virtual_td_dydesc = 0,
    uint64_t virtual_cd_convdesc = 0,
    uint64_t virtual_td_dxdesc = 0,
    int32_t requested_algo_count = 0,
    int32_t returned_algo_count = 0,
    const std::vector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>> *perf_results = nullptr) {
  auto perf_results__ = perf_results ? _fbb.CreateVector<flatbuffers::Offset<FBCudnnConvolutionBwdDataAlgoPerf>>(*perf_results) : 0;
  return CreateFBCudnnGetConvolutionBackwardDataAlgorithmV7(
      _fbb,
      virtual_handle,
      virtual_fd_wdesc,
      virtual_td_dydesc,
      virtual_cd_convdesc,
      virtual_td_dxdesc,
      requested_algo_count,
      returned_algo_count,
      perf_results__);
}

struct FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSizeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_MODE = 6,
    VT_BN_OPS = 8,
    VT_VIRTUAL_TD_XDESC = 10,
    VT_VIRTUAL_TD_ZDESC = 12,
    VT_VIRTUAL_TD_YDESC = 14,
    VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC = 16,
    VT_VIRTUAL_AD_ACTIVATION_DESC = 18,
    VT_SIZE_IN_BYTES = 20
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t mode() const {
    return GetField<uint64_t>(VT_MODE, 0);
  }
  uint64_t bn_ops() const {
    return GetField<uint64_t>(VT_BN_OPS, 0);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t virtual_td_zdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_ZDESC, 0);
  }
  uint64_t virtual_td_ydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_YDESC, 0);
  }
  uint64_t virtual_td_bn_scale_bias_mean_var_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC, 0);
  }
  uint64_t virtual_ad_activation_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_AD_ACTIVATION_DESC, 0);
  }
  uint64_t size_in_bytes() const {
    return GetField<uint64_t>(VT_SIZE_IN_BYTES, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_MODE) &&
           VerifyField<uint64_t>(verifier, VT_BN_OPS) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_ZDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_YDESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_AD_ACTIVATION_DESC) &&
           VerifyField<uint64_t>(verifier, VT_SIZE_IN_BYTES) &&
           verifier.EndTable();
  }
};

struct FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSizeBuilder {
  typedef FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_mode(uint64_t mode) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_MODE, mode, 0);
  }
  void add_bn_ops(uint64_t bn_ops) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_BN_OPS, bn_ops, 0);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_virtual_td_zdesc(uint64_t virtual_td_zdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_TD_ZDESC, virtual_td_zdesc, 0);
  }
  void add_virtual_td_ydesc(uint64_t virtual_td_ydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_TD_YDESC, virtual_td_ydesc, 0);
  }
  void add_virtual_td_bn_scale_bias_mean_var_desc(uint64_t virtual_td_bn_scale_bias_mean_var_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC, virtual_td_bn_scale_bias_mean_var_desc, 0);
  }
  void add_virtual_ad_activation_desc(uint64_t virtual_ad_activation_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_VIRTUAL_AD_ACTIVATION_DESC, virtual_ad_activation_desc, 0);
  }
  void add_size_in_bytes(uint64_t size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize::VT_SIZE_IN_BYTES, size_in_bytes, 0);
  }
  explicit FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize> CreateFBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    uint64_t bn_ops = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t virtual_td_zdesc = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t virtual_td_bn_scale_bias_mean_var_desc = 0,
    uint64_t virtual_ad_activation_desc = 0,
    uint64_t size_in_bytes = 0) {
  FBCudnnGetBatchNormalizationForwardTrainingExWorkspaceSizeBuilder builder_(_fbb);
  builder_.add_size_in_bytes(size_in_bytes);
  builder_.add_virtual_ad_activation_desc(virtual_ad_activation_desc);
  builder_.add_virtual_td_bn_scale_bias_mean_var_desc(virtual_td_bn_scale_bias_mean_var_desc);
  builder_.add_virtual_td_ydesc(virtual_td_ydesc);
  builder_.add_virtual_td_zdesc(virtual_td_zdesc);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_bn_ops(bn_ops);
  builder_.add_mode(mode);
  builder_.add_virtual_handle(virtual_handle);
  return builder_.Finish();
}

struct FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnGetBatchNormalizationTrainingExReserveSpaceSizeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_MODE = 6,
    VT_BN_OPS = 8,
    VT_VIRTUAL_AD_ACTIVATION_DESC = 10,
    VT_VIRTUAL_TD_XDESC = 12,
    VT_SIZE_IN_BYTES = 14
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t mode() const {
    return GetField<uint64_t>(VT_MODE, 0);
  }
  uint64_t bn_ops() const {
    return GetField<uint64_t>(VT_BN_OPS, 0);
  }
  uint64_t virtual_ad_activation_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_AD_ACTIVATION_DESC, 0);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t size_in_bytes() const {
    return GetField<uint64_t>(VT_SIZE_IN_BYTES, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_MODE) &&
           VerifyField<uint64_t>(verifier, VT_BN_OPS) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_AD_ACTIVATION_DESC) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_SIZE_IN_BYTES) &&
           verifier.EndTable();
  }
};

struct FBCudnnGetBatchNormalizationTrainingExReserveSpaceSizeBuilder {
  typedef FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_mode(uint64_t mode) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_MODE, mode, 0);
  }
  void add_bn_ops(uint64_t bn_ops) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_BN_OPS, bn_ops, 0);
  }
  void add_virtual_ad_activation_desc(uint64_t virtual_ad_activation_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_VIRTUAL_AD_ACTIVATION_DESC, virtual_ad_activation_desc, 0);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_size_in_bytes(uint64_t size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize::VT_SIZE_IN_BYTES, size_in_bytes, 0);
  }
  explicit FBCudnnGetBatchNormalizationTrainingExReserveSpaceSizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnGetBatchNormalizationTrainingExReserveSpaceSize> CreateFBCudnnGetBatchNormalizationTrainingExReserveSpaceSize(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    uint64_t bn_ops = 0,
    uint64_t virtual_ad_activation_desc = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t size_in_bytes = 0) {
  FBCudnnGetBatchNormalizationTrainingExReserveSpaceSizeBuilder builder_(_fbb);
  builder_.add_size_in_bytes(size_in_bytes);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_virtual_ad_activation_desc(virtual_ad_activation_desc);
  builder_.add_bn_ops(bn_ops);
  builder_.add_mode(mode);
  builder_.add_virtual_handle(virtual_handle);
  return builder_.Finish();
}

struct FBCudnnBatchNormalizationForwardTrainingEx FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FBCudnnBatchNormalizationForwardTrainingExBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VIRTUAL_HANDLE = 4,
    VT_MODE = 6,
    VT_BN_OPS = 8,
    VT_ALPHA = 10,
    VT_BETA = 12,
    VT_VIRTUAL_TD_XDESC = 14,
    VT_X_DATA = 16,
    VT_VIRTUAL_TD_YDESC = 18,
    VT_Y_DATA = 20,
    VT_VIRTUAL_TD_ZDESC = 22,
    VT_Z_DATA = 24,
    VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC = 26,
    VT_BN_SCALE_DATA = 28,
    VT_BN_BIAS_DATA = 30,
    VT_EXPONENTIAL_AVERAGE_FACTOR = 32,
    VT_RESULT_RUNNING_MEAN_DATA = 34,
    VT_RESULT_RUNNING_VARIANCE_DATA = 36,
    VT_EPSILON = 38,
    VT_SAVE_MEAN = 40,
    VT_SAVE_INV_VARIANCE = 42,
    VT_VIRTUAL_AD_ACTIVATION_DESC = 44,
    VT_WORKSPACE = 46,
    VT_WORKSPACE_SIZE_IN_BYTES = 48,
    VT_RESERVE_SPACE = 50,
    VT_RESERVE_SPACE_SIZE_IN_BYTES = 52
  };
  uint64_t virtual_handle() const {
    return GetField<uint64_t>(VT_VIRTUAL_HANDLE, 0);
  }
  uint64_t mode() const {
    return GetField<uint64_t>(VT_MODE, 0);
  }
  uint64_t bn_ops() const {
    return GetField<uint64_t>(VT_BN_OPS, 0);
  }
  const flatbuffers::Vector<uint8_t> *alpha() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_ALPHA);
  }
  const flatbuffers::Vector<uint8_t> *beta() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_BETA);
  }
  uint64_t virtual_td_xdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_XDESC, 0);
  }
  uint64_t x_data() const {
    return GetField<uint64_t>(VT_X_DATA, 0);
  }
  uint64_t virtual_td_ydesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_YDESC, 0);
  }
  uint64_t y_data() const {
    return GetField<uint64_t>(VT_Y_DATA, 0);
  }
  uint64_t virtual_td_zdesc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_ZDESC, 0);
  }
  uint64_t z_data() const {
    return GetField<uint64_t>(VT_Z_DATA, 0);
  }
  uint64_t virtual_td_bn_scale_bias_mean_var_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC, 0);
  }
  uint64_t bn_scale_data() const {
    return GetField<uint64_t>(VT_BN_SCALE_DATA, 0);
  }
  uint64_t bn_bias_data() const {
    return GetField<uint64_t>(VT_BN_BIAS_DATA, 0);
  }
  double exponential_average_factor() const {
    return GetField<double>(VT_EXPONENTIAL_AVERAGE_FACTOR, 0.0);
  }
  uint64_t result_running_mean_data() const {
    return GetField<uint64_t>(VT_RESULT_RUNNING_MEAN_DATA, 0);
  }
  uint64_t result_running_variance_data() const {
    return GetField<uint64_t>(VT_RESULT_RUNNING_VARIANCE_DATA, 0);
  }
  double epsilon() const {
    return GetField<double>(VT_EPSILON, 0.0);
  }
  uint64_t save_mean() const {
    return GetField<uint64_t>(VT_SAVE_MEAN, 0);
  }
  uint64_t save_inv_variance() const {
    return GetField<uint64_t>(VT_SAVE_INV_VARIANCE, 0);
  }
  uint64_t virtual_ad_activation_desc() const {
    return GetField<uint64_t>(VT_VIRTUAL_AD_ACTIVATION_DESC, 0);
  }
  uint64_t workspace() const {
    return GetField<uint64_t>(VT_WORKSPACE, 0);
  }
  uint64_t workspace_size_in_bytes() const {
    return GetField<uint64_t>(VT_WORKSPACE_SIZE_IN_BYTES, 0);
  }
  uint64_t reserve_space() const {
    return GetField<uint64_t>(VT_RESERVE_SPACE, 0);
  }
  uint64_t reserve_space_size_in_bytes() const {
    return GetField<uint64_t>(VT_RESERVE_SPACE_SIZE_IN_BYTES, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_HANDLE) &&
           VerifyField<uint64_t>(verifier, VT_MODE) &&
           VerifyField<uint64_t>(verifier, VT_BN_OPS) &&
           VerifyOffset(verifier, VT_ALPHA) &&
           verifier.VerifyVector(alpha()) &&
           VerifyOffset(verifier, VT_BETA) &&
           verifier.VerifyVector(beta()) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_XDESC) &&
           VerifyField<uint64_t>(verifier, VT_X_DATA) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_YDESC) &&
           VerifyField<uint64_t>(verifier, VT_Y_DATA) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_ZDESC) &&
           VerifyField<uint64_t>(verifier, VT_Z_DATA) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC) &&
           VerifyField<uint64_t>(verifier, VT_BN_SCALE_DATA) &&
           VerifyField<uint64_t>(verifier, VT_BN_BIAS_DATA) &&
           VerifyField<double>(verifier, VT_EXPONENTIAL_AVERAGE_FACTOR) &&
           VerifyField<uint64_t>(verifier, VT_RESULT_RUNNING_MEAN_DATA) &&
           VerifyField<uint64_t>(verifier, VT_RESULT_RUNNING_VARIANCE_DATA) &&
           VerifyField<double>(verifier, VT_EPSILON) &&
           VerifyField<uint64_t>(verifier, VT_SAVE_MEAN) &&
           VerifyField<uint64_t>(verifier, VT_SAVE_INV_VARIANCE) &&
           VerifyField<uint64_t>(verifier, VT_VIRTUAL_AD_ACTIVATION_DESC) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE) &&
           VerifyField<uint64_t>(verifier, VT_WORKSPACE_SIZE_IN_BYTES) &&
           VerifyField<uint64_t>(verifier, VT_RESERVE_SPACE) &&
           VerifyField<uint64_t>(verifier, VT_RESERVE_SPACE_SIZE_IN_BYTES) &&
           verifier.EndTable();
  }
};

struct FBCudnnBatchNormalizationForwardTrainingExBuilder {
  typedef FBCudnnBatchNormalizationForwardTrainingEx Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_virtual_handle(uint64_t virtual_handle) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_HANDLE, virtual_handle, 0);
  }
  void add_mode(uint64_t mode) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_MODE, mode, 0);
  }
  void add_bn_ops(uint64_t bn_ops) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_BN_OPS, bn_ops, 0);
  }
  void add_alpha(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha) {
    fbb_.AddOffset(FBCudnnBatchNormalizationForwardTrainingEx::VT_ALPHA, alpha);
  }
  void add_beta(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta) {
    fbb_.AddOffset(FBCudnnBatchNormalizationForwardTrainingEx::VT_BETA, beta);
  }
  void add_virtual_td_xdesc(uint64_t virtual_td_xdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_TD_XDESC, virtual_td_xdesc, 0);
  }
  void add_x_data(uint64_t x_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_X_DATA, x_data, 0);
  }
  void add_virtual_td_ydesc(uint64_t virtual_td_ydesc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_TD_YDESC, virtual_td_ydesc, 0);
  }
  void add_y_data(uint64_t y_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_Y_DATA, y_data, 0);
  }
  void add_virtual_td_zdesc(uint64_t virtual_td_zdesc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_TD_ZDESC, virtual_td_zdesc, 0);
  }
  void add_z_data(uint64_t z_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_Z_DATA, z_data, 0);
  }
  void add_virtual_td_bn_scale_bias_mean_var_desc(uint64_t virtual_td_bn_scale_bias_mean_var_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_TD_BN_SCALE_BIAS_MEAN_VAR_DESC, virtual_td_bn_scale_bias_mean_var_desc, 0);
  }
  void add_bn_scale_data(uint64_t bn_scale_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_BN_SCALE_DATA, bn_scale_data, 0);
  }
  void add_bn_bias_data(uint64_t bn_bias_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_BN_BIAS_DATA, bn_bias_data, 0);
  }
  void add_exponential_average_factor(double exponential_average_factor) {
    fbb_.AddElement<double>(FBCudnnBatchNormalizationForwardTrainingEx::VT_EXPONENTIAL_AVERAGE_FACTOR, exponential_average_factor, 0.0);
  }
  void add_result_running_mean_data(uint64_t result_running_mean_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_RESULT_RUNNING_MEAN_DATA, result_running_mean_data, 0);
  }
  void add_result_running_variance_data(uint64_t result_running_variance_data) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_RESULT_RUNNING_VARIANCE_DATA, result_running_variance_data, 0);
  }
  void add_epsilon(double epsilon) {
    fbb_.AddElement<double>(FBCudnnBatchNormalizationForwardTrainingEx::VT_EPSILON, epsilon, 0.0);
  }
  void add_save_mean(uint64_t save_mean) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_SAVE_MEAN, save_mean, 0);
  }
  void add_save_inv_variance(uint64_t save_inv_variance) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_SAVE_INV_VARIANCE, save_inv_variance, 0);
  }
  void add_virtual_ad_activation_desc(uint64_t virtual_ad_activation_desc) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_VIRTUAL_AD_ACTIVATION_DESC, virtual_ad_activation_desc, 0);
  }
  void add_workspace(uint64_t workspace) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_WORKSPACE, workspace, 0);
  }
  void add_workspace_size_in_bytes(uint64_t workspace_size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_WORKSPACE_SIZE_IN_BYTES, workspace_size_in_bytes, 0);
  }
  void add_reserve_space(uint64_t reserve_space) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_RESERVE_SPACE, reserve_space, 0);
  }
  void add_reserve_space_size_in_bytes(uint64_t reserve_space_size_in_bytes) {
    fbb_.AddElement<uint64_t>(FBCudnnBatchNormalizationForwardTrainingEx::VT_RESERVE_SPACE_SIZE_IN_BYTES, reserve_space_size_in_bytes, 0);
  }
  explicit FBCudnnBatchNormalizationForwardTrainingExBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FBCudnnBatchNormalizationForwardTrainingEx> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FBCudnnBatchNormalizationForwardTrainingEx>(end);
    return o;
  }
};

inline flatbuffers::Offset<FBCudnnBatchNormalizationForwardTrainingEx> CreateFBCudnnBatchNormalizationForwardTrainingEx(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    uint64_t bn_ops = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> alpha = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> beta = 0,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x_data = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y_data = 0,
    uint64_t virtual_td_zdesc = 0,
    uint64_t z_data = 0,
    uint64_t virtual_td_bn_scale_bias_mean_var_desc = 0,
    uint64_t bn_scale_data = 0,
    uint64_t bn_bias_data = 0,
    double exponential_average_factor = 0.0,
    uint64_t result_running_mean_data = 0,
    uint64_t result_running_variance_data = 0,
    double epsilon = 0.0,
    uint64_t save_mean = 0,
    uint64_t save_inv_variance = 0,
    uint64_t virtual_ad_activation_desc = 0,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    uint64_t reserve_space = 0,
    uint64_t reserve_space_size_in_bytes = 0) {
  FBCudnnBatchNormalizationForwardTrainingExBuilder builder_(_fbb);
  builder_.add_reserve_space_size_in_bytes(reserve_space_size_in_bytes);
  builder_.add_reserve_space(reserve_space);
  builder_.add_workspace_size_in_bytes(workspace_size_in_bytes);
  builder_.add_workspace(workspace);
  builder_.add_virtual_ad_activation_desc(virtual_ad_activation_desc);
  builder_.add_save_inv_variance(save_inv_variance);
  builder_.add_save_mean(save_mean);
  builder_.add_epsilon(epsilon);
  builder_.add_result_running_variance_data(result_running_variance_data);
  builder_.add_result_running_mean_data(result_running_mean_data);
  builder_.add_exponential_average_factor(exponential_average_factor);
  builder_.add_bn_bias_data(bn_bias_data);
  builder_.add_bn_scale_data(bn_scale_data);
  builder_.add_virtual_td_bn_scale_bias_mean_var_desc(virtual_td_bn_scale_bias_mean_var_desc);
  builder_.add_z_data(z_data);
  builder_.add_virtual_td_zdesc(virtual_td_zdesc);
  builder_.add_y_data(y_data);
  builder_.add_virtual_td_ydesc(virtual_td_ydesc);
  builder_.add_x_data(x_data);
  builder_.add_virtual_td_xdesc(virtual_td_xdesc);
  builder_.add_bn_ops(bn_ops);
  builder_.add_mode(mode);
  builder_.add_virtual_handle(virtual_handle);
  builder_.add_beta(beta);
  builder_.add_alpha(alpha);
  return builder_.Finish();
}

inline flatbuffers::Offset<FBCudnnBatchNormalizationForwardTrainingEx> CreateFBCudnnBatchNormalizationForwardTrainingExDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t virtual_handle = 0,
    uint64_t mode = 0,
    uint64_t bn_ops = 0,
    const std::vector<uint8_t> *alpha = nullptr,
    const std::vector<uint8_t> *beta = nullptr,
    uint64_t virtual_td_xdesc = 0,
    uint64_t x_data = 0,
    uint64_t virtual_td_ydesc = 0,
    uint64_t y_data = 0,
    uint64_t virtual_td_zdesc = 0,
    uint64_t z_data = 0,
    uint64_t virtual_td_bn_scale_bias_mean_var_desc = 0,
    uint64_t bn_scale_data = 0,
    uint64_t bn_bias_data = 0,
    double exponential_average_factor = 0.0,
    uint64_t result_running_mean_data = 0,
    uint64_t result_running_variance_data = 0,
    double epsilon = 0.0,
    uint64_t save_mean = 0,
    uint64_t save_inv_variance = 0,
    uint64_t virtual_ad_activation_desc = 0,
    uint64_t workspace = 0,
    uint64_t workspace_size_in_bytes = 0,
    uint64_t reserve_space = 0,
    uint64_t reserve_space_size_in_bytes = 0) {
  auto alpha__ = alpha ? _fbb.CreateVector<uint8_t>(*alpha) : 0;
  auto beta__ = beta ? _fbb.CreateVector<uint8_t>(*beta) : 0;
  return CreateFBCudnnBatchNormalizationForwardTrainingEx(
      _fbb,
      virtual_handle,
      mode,
      bn_ops,
      alpha__,
      beta__,
      virtual_td_xdesc,
      x_data,
      virtual_td_ydesc,
      y_data,
      virtual_td_zdesc,
      z_data,
      virtual_td_bn_scale_bias_mean_var_desc,
      bn_scale_data,
      bn_bias_data,
      exponential_average_factor,
      result_running_mean_data,
      result_running_variance_data,
      epsilon,
      save_mean,
      save_inv_variance,
      virtual_ad_activation_desc,
      workspace,
      workspace_size_in_bytes,
      reserve_space,
      reserve_space_size_in_bytes);
}

#endif  // FLATBUFFERS_GENERATED_CUDNNCALLS_H_
